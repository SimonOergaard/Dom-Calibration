[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2025-01-20 10:18:12 - IceCubeUpgrade.__init__ - Writing log to [1mlogs/graphnet_20250120-101812.log[0m
[1;34mgraphnet[0m [MainProcess] [33mWARNING [0m 2025-01-20 10:18:12 - SQLiteDataset.__init__ - Dataset is empty.[0m
[1;34mgraphnet[0m [MainProcess] [33mWARNING [0m 2025-01-20 10:18:12 - StandardModel.main - DeprecationWarning: Argument `gnn` will be deprecated in GraphNeT 2.0. Please use `backbone` instead.[0m
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name              | Type       | Params | Mode 
---------------------------------------------------------
0 | _tasks            | ModuleList | 387    | train
1 | _graph_definition | KNNGraph   | 0      | train
2 | backbone          | DynEdge    | 1.4 M  | train
---------------------------------------------------------
1.4 M     Trainable params
0         Non-trainable params
1.4 M     Total params
5.568     Total estimated model params size (MB)
35        Modules in train mode
0         Modules in eval mode
`Trainer.fit` stopped: No training batches.
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2025-01-20 10:18:14 - StandardModel.<module> - Model state_dict saved to /groups/icecube/simon/GNN/workspace/Models/model_state.pth[0m
[1;34mgraphnet[0m [MainProcess] [32mINFO    [0m 2025-01-20 10:18:14 - StandardModel.<module> - Column names for predictions are: 
 ['position_x_pred', 'position_y_pred', 'position_z_pred'][0m
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
